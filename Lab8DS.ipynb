{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae8a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: pyreadstat in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\javier chiquin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: narwhals>=2.0 in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyreadstat) (2.6.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\javier chiquin\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas pyreadstat openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9f2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo SPSS '2021.sav' cargado exitosamente. Se encontraron 10544 registros.\n",
      "✅ Conversión finalizada. El archivo Excel se guardó en: c:\\Users\\Javier Chiquin\\OneDrive\\Documents\\UVG\\Cuarto año\\Segundo Semestre\\Data Science\\Lab8DS\\2021.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Configuración de Archivos ---\n",
    "# Reemplaza 'nombre_archivo.sav' con la ruta y nombre de tu archivo SPSS\n",
    "archivo_spss = '2021.sav'\n",
    "# Reemplaza 'salida.xlsx' con el nombre que deseas para el archivo Excel\n",
    "archivo_excel = '2021.xlsx'\n",
    "\n",
    "# --- 1. Lectura del archivo SPSS (.sav) ---\n",
    "try:\n",
    "    # pd.read_spss() lee el archivo SPSS y lo convierte en un DataFrame de pandas\n",
    "    # Si tu archivo tiene etiquetas de valor (value labels),\n",
    "    # puedes usar pyreadstat directamente para manejarlas,\n",
    "    # pero para una conversión simple, read_spss() es suficiente.\n",
    "    df = pd.read_spss(archivo_spss)\n",
    "    print(f\"✅ Archivo SPSS '{archivo_spss}' cargado exitosamente. Se encontraron {len(df)} registros.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: No se encontró el archivo '{archivo_spss}'.\")\n",
    "    exit()\n",
    "except ImportError:\n",
    "    print(\"❌ ERROR: La librería 'pyreadstat' no está instalada o falló al cargar el archivo.\")\n",
    "    print(\"Por favor, ejecuta: pip install pyreadstat\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ocurrió un error al leer el archivo SPSS: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Escritura en formato Excel (.xlsx) ---\n",
    "try:\n",
    "    # .to_excel() guarda el DataFrame de pandas en un archivo Excel.\n",
    "    # index=False evita escribir el índice del DataFrame como una columna en Excel.\n",
    "    df.to_excel(archivo_excel, index=False)\n",
    "\n",
    "    ruta_absoluta = os.path.abspath(archivo_excel)\n",
    "    print(f\"✅ Conversión finalizada. El archivo Excel se guardó en: {ruta_absoluta}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"❌ ERROR: La librería 'openpyxl' no está instalada.\")\n",
    "    print(\"Por favor, ejecuta: pip install openpyxl\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ocurrió un error al escribir el archivo Excel: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077c1dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\javier chiquin\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\javier chiquin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\javier chiquin\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abb7d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando la concatenación de archivos Excel de 2014 a 2023...\n",
      "   ✅ Leído: 2014.xlsx\n",
      "   ✅ Leído: 2015.xlsx\n",
      "   ✅ Leído: 2016.xlsx\n",
      "   ✅ Leído: 2017.xlsx\n",
      "   ✅ Leído: 2018.xlsx\n",
      "   ✅ Leído: 2019.xlsx\n",
      "   ✅ Leído: 2020.xlsx\n",
      "   ✅ Leído: 2021.xlsx\n",
      "   ✅ Leído: 2022.xlsx\n",
      "   ✅ Leído: 2023.xlsx\n",
      "\n",
      "--- RESUMEN ---\n",
      "✅ CONCATENACIÓN EXITOSA: Se unieron 10 archivos.\n",
      "Total de filas en el archivo final: 100357\n",
      "Archivo guardado como: c:\\Users\\Javier Chiquin\\OneDrive\\Documents\\UVG\\Cuarto año\\Segundo Semestre\\Data Science\\Lab8DS\\fallecimientos_lesionados_totales.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# --- Configuración de Parámetros ---\n",
    "\n",
    "# Define el rango de años de tus archivos\n",
    "ANIO_INICIO = 2014\n",
    "ANIO_FIN = 2023\n",
    "\n",
    "# Nombre del archivo de salida\n",
    "NOMBRE_SALIDA = 'fallecimientos_lesionados_totales.xlsx'\n",
    "\n",
    "# Lista para almacenar todos los DataFrames\n",
    "todos_los_datos = []\n",
    "archivos_encontrados = 0\n",
    "\n",
    "print(f\"Iniciando la concatenación de archivos Excel de {ANIO_INICIO} a {ANIO_FIN}...\")\n",
    "\n",
    "# --- Proceso de Lectura y Concatenación ---\n",
    "\n",
    "for anio in range(ANIO_INICIO, ANIO_FIN + 1):\n",
    "    # Crea un patrón de búsqueda para el archivo de cada año\n",
    "    # Por ejemplo: '*2014*.xlsx', '*2015*.xlsx', etc.\n",
    "    patron_busqueda = f'*{anio}*.xlsx'\n",
    "    \n",
    "    # Busca el archivo que coincida con el patrón. glob.glob devuelve una lista.\n",
    "    # Se toma el primer archivo encontrado con ese año.\n",
    "    archivo = glob.glob(patron_busqueda)\n",
    "\n",
    "    if archivo:\n",
    "        ruta_archivo = archivo[0]\n",
    "        try:\n",
    "            # Lee el archivo Excel. Por defecto, lee la primera hoja.\n",
    "            # Si tus datos están en una hoja específica (ej: 'Hoja1'), usa:\n",
    "            # df_temp = pd.read_excel(ruta_archivo, sheet_name='Hoja1')\n",
    "            df_temp = pd.read_excel(ruta_archivo)\n",
    "            \n",
    "            # **OPCIONAL:** Agrega una columna de Año para saber a qué archivo pertenecía cada registro\n",
    "            df_temp['Año_Origen'] = anio\n",
    "            \n",
    "            # Agrega el DataFrame temporal a la lista\n",
    "            todos_los_datos.append(df_temp)\n",
    "            archivos_encontrados += 1\n",
    "            print(f\"   ✅ Leído: {os.path.basename(ruta_archivo)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ ERROR al leer {ruta_archivo}: {e}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"   ⚠️ Advertencia: No se encontró ningún archivo para el año {anio} con el patrón '{patron_busqueda}'\")\n",
    "\n",
    "# Verifica si se encontró algún archivo\n",
    "if not todos_los_datos:\n",
    "    print(\"\\n❌ FINALIZADO: No se encontró ningún archivo para concatenar. Verifica tus nombres de archivo.\")\n",
    "else:\n",
    "    # Concatena todos los DataFrames de la lista en uno solo\n",
    "    df_final = pd.concat(todos_los_datos, ignore_index=True)\n",
    "    \n",
    "    # --- Escritura del Archivo Final ---\n",
    "    try:\n",
    "        df_final.to_excel(NOMBRE_SALIDA, index=False)\n",
    "        ruta_absoluta = os.path.abspath(NOMBRE_SALIDA)\n",
    "        \n",
    "        print(\"\\n--- RESUMEN ---\")\n",
    "        print(f\"✅ CONCATENACIÓN EXITOSA: Se unieron {archivos_encontrados} archivos.\")\n",
    "        print(f\"Total de filas en el archivo final: {len(df_final)}\")\n",
    "        print(f\"Archivo guardado como: {ruta_absoluta}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ ERROR al escribir el archivo final '{NOMBRE_SALIDA}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50783cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo. Archivo limpio guardado en: fallecimientos_lesionados_totales_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# RUTAS DE ENTRADA/SALIDA\n",
    "# =========================\n",
    "PATH_DICT = \"akJPkytmTlGr1QQoommBxUNXhZ9Qhwph.xlsx\"            # \"excel con nombre raro\" (diccionario)\n",
    "PATH_FALLE = \"fallecimientos_lesionados_totales.xlsx\"          # archivo unificado 2014–2023\n",
    "SHEET_FALLE = \"Sheet1\"                                         # ajusta si tu hoja tiene otro nombre\n",
    "OUT_CSV = \"fallecimientos_lesionados_totales_clean.csv\"        # salida limpia (CSV)\n",
    "# OUT_XLSX = \"fallecimientos_lesionados_totales_clean.xlsx\"    # si prefieres Excel, descomenta y usa to_excel\n",
    "\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES\n",
    "# =========================\n",
    "def _normalize_str(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    s = str(x).strip()\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def _parse_dictionary(path_dict: str) -> dict:\n",
    "    \"\"\"\n",
    "    Lee el diccionario (una hoja con varios bloques) y devuelve:\n",
    "    maps = { 'Nombre de Variable' : { 'codigo': 'etiqueta', ... }, ... }\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(path_dict, sheet_name=0)\n",
    "    # Renombrar columnas genéricas detectadas\n",
    "    cols = list(df.columns)\n",
    "    # Esperado: [col0, codigo, etiqueta, extra], aunque los nombres reales vienen \"raros\"\n",
    "    # Tomamos la primera como 'col0', segunda 'codigo', tercera 'etiqueta', cuarta 'extra'\n",
    "    ren = {}\n",
    "    if len(cols) >= 1: ren[cols[0]] = \"col0\"\n",
    "    if len(cols) >= 2: ren[cols[1]] = \"codigo\"\n",
    "    if len(cols) >= 3: ren[cols[2]] = \"etiqueta\"\n",
    "    if len(cols) >= 4: ren[cols[3]] = \"extra\"\n",
    "    df = df.rename(columns=ren)\n",
    "\n",
    "    # Nombre de variable en col0, y las filas de datos tienen 'codigo' numérico y 'etiqueta'\n",
    "    df[\"var\"] = df[\"col0\"].where(df[\"col0\"].notna(), None)\n",
    "    # Filas con \"Valor\" son encabezado del sub-bloque: no es nombre de variable\n",
    "    df[\"var\"] = df[\"var\"].mask(df[\"var\"].eq(\"Valor\")).ffill()\n",
    "\n",
    "    # Filas que realmente son códigos (número)\n",
    "    def _is_digit_like(x):\n",
    "        s = str(x).strip()\n",
    "        # acepta enteros y enteros con .0\n",
    "        try:\n",
    "            int(float(s))\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    mask_codes = df[\"codigo\"].apply(_is_digit_like)\n",
    "    maps = {}\n",
    "    for var, sub in df[mask_codes].groupby(\"var\"):\n",
    "        # código → etiqueta (todo a str y sin espacios raros)\n",
    "        mapping = {}\n",
    "        for c, e in zip(sub[\"codigo\"], sub[\"etiqueta\"]):\n",
    "            if pd.isna(c): \n",
    "                continue\n",
    "            key = str(int(float(str(c).strip())))\n",
    "            val = _normalize_str(e)\n",
    "            mapping[key] = val\n",
    "        maps[_normalize_str(var)] = mapping\n",
    "    return maps\n",
    "\n",
    "def _map_to_label(series: pd.Series, mapping: dict) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convierte códigos a etiquetas usando 'mapping'.\n",
    "    Si el valor ya es etiqueta (aparece en mapping.values()), lo deja igual.\n",
    "    Si no encuentra match, deja el valor original.\n",
    "    \"\"\"\n",
    "    if not mapping:\n",
    "        return series\n",
    "    label_set = set(mapping.values())\n",
    "\n",
    "    def convert(v):\n",
    "        if pd.isna(v):\n",
    "            return v\n",
    "        v_norm = _normalize_str(v)\n",
    "\n",
    "        # Ya es etiqueta conocida\n",
    "        if v_norm in label_set:\n",
    "            return v_norm\n",
    "\n",
    "        # Intentar por código (acepta \"1\", \"01\", 1.0, etc.)\n",
    "        key = None\n",
    "        try:\n",
    "            key = str(int(float(v_norm)))\n",
    "        except:\n",
    "            key = v_norm  # por si viene como string exacto del código\n",
    "\n",
    "        return mapping.get(key, v_norm)\n",
    "\n",
    "    return series.apply(convert)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CARGA DICCIONARIO\n",
    "# =========================\n",
    "maps = _parse_dictionary(PATH_DICT)\n",
    "\n",
    "# Puente entre nombres de columnas del dataset y nombres de variables en el diccionario\n",
    "BRIDGE = {\n",
    "    \"día_sem_ocu\": \"Día de la semana de ocurrencia\",\n",
    "    \"g_hora\": \"Grupo de hora\",\n",
    "    \"mes_ocu\": \"Mes de ocurrencia\",\n",
    "\n",
    "    # territoriales (mantener por nombre SIEMPRE)\n",
    "    \"depto_ocu\": \"Departamento\",\n",
    "    \"mupio_ocu\": \"Municipio de ocurrencia\",\n",
    "\n",
    "    \"zona_ocu\": \"Zona de ocurrencia\",\n",
    "    \"área_geo_ocu\": \"Área geográfica\",\n",
    "\n",
    "    # víctima/persona\n",
    "    \"sexo_víc\": \"Sexo de la víctima\",\n",
    "    \"sexo_per\": \"Sexo de la víctima\",      # en algunas bases usan *_per\n",
    "    \"g_edad\": \"Grupo de edad\",\n",
    "    \"mayor_menor\": \"Mayor o menor\",\n",
    "\n",
    "    # evento/vehículo\n",
    "    \"tipo_eve\": \"Tipo de evento\",\n",
    "    \"tipo_acc\": \"Tipo de evento\",\n",
    "    \"tipo_veh\": \"Tipo de vehículo\",\n",
    "    \"color_veh\": \"Color del vehículo\",\n",
    "    \"marca_veh\": \"Marca del vehículo\",\n",
    "    \"g_modelo_veh\": \"Modelo del vehículo\",\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# CARGA Y LIMPIEZA\n",
    "# =========================\n",
    "df = pd.read_excel(PATH_FALLE, sheet_name=SHEET_FALLE)\n",
    "\n",
    "# 1) Normalizar strings (trim/espacios múltiples) sin tocar numéricos\n",
    "for c in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    df[c] = df[c].map(_normalize_str)\n",
    "\n",
    "# 2) Aplicar mapeos: SIEMPRE a etiqueta (nunca códigos)\n",
    "for col, dict_var in BRIDGE.items():\n",
    "    if col in df.columns:\n",
    "        mapping = maps.get(dict_var, {})\n",
    "        df[col] = _map_to_label(df[col], mapping)\n",
    "\n",
    "# 3) (Opcional) Si quieres forzar que 'hora_ocu' y 'día_ocu' queden como enteros limpios:\n",
    "# for c in [\"hora_ocu\", \"día_ocu\"]:\n",
    "#     if c in df.columns:\n",
    "#         df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# =========================\n",
    "# GUARDAR SALIDA\n",
    "# =========================\n",
    "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "# Si prefieres Excel (más pesado/lento en archivos grandes), usa:\n",
    "# df.to_excel(OUT_XLSX, index=False)\n",
    "print(\"Listo. Archivo limpio guardado en:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3598ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de columnas: 25\n",
      "núm_corre\n",
      "año_ocu\n",
      "día_ocu\n",
      "hora_ocu\n",
      "g_hora\n",
      "g_hora_5\n",
      "mes_ocu\n",
      "día_sem_ocu\n",
      "depto_ocu\n",
      "mupio_ocu\n",
      "zona_ocu\n",
      "sexo_per\n",
      "edad_per\n",
      "g_edad_80ymás\n",
      "g_edad_60ymás\n",
      "edad_quinquenales\n",
      "mayor_menor\n",
      "tipo_veh\n",
      "marca_veh\n",
      "color_veh\n",
      "modelo_veh\n",
      "g_modelo_veh\n",
      "tipo_eve\n",
      "fall_les\n",
      "int_o_noint\n",
      "\n",
      "Archivo de columnas guardado en: 2023_Sheet1_columnas.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def desglosar_columnas(path_archivo: str, sheet: str | None = None, encoding: str = \"utf-8\", guardar_txt: bool = False, path_salida: str | None = None):\n",
    "    \"\"\"\n",
    "    Lee SOLO los nombres de columnas de un CSV o Excel (.xlsx/.xls) y los devuelve como lista.\n",
    "    - path_archivo: ruta al archivo\n",
    "    - sheet: nombre de hoja (solo Excel). Si None, usa la primera hoja\n",
    "    - encoding: codificación para CSV (por defecto 'utf-8')\n",
    "    - guardar_txt: si True, guarda los nombres en un .txt\n",
    "    - path_salida: ruta del .txt a guardar. Si None, crea uno al lado del archivo\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(path_archivo)[1].lower()\n",
    "\n",
    "    if ext == \".csv\":\n",
    "        # Solo encabezado (rápido y liviano)\n",
    "        df = pd.read_csv(path_archivo, nrows=0, encoding=encoding)\n",
    "    elif ext in [\".xlsx\", \".xls\"]:\n",
    "        if sheet is None:\n",
    "            # Detectar primera hoja automáticamente\n",
    "            xls = pd.ExcelFile(path_archivo)\n",
    "            sheet = xls.sheet_names[0]\n",
    "        df = pd.read_excel(path_archivo, sheet_name=sheet, nrows=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Extensión no soportada: {ext}. Usa CSV o Excel (.xlsx/.xls).\")\n",
    "\n",
    "    columnas = list(map(str, df.columns))\n",
    "\n",
    "    # Mostrar en el notebook (orden natural)\n",
    "    print(f\"Total de columnas: {len(columnas)}\")\n",
    "    for c in columnas:\n",
    "        print(c)\n",
    "\n",
    "    # Guardar opcionalmente\n",
    "    if guardar_txt:\n",
    "        if path_salida is None:\n",
    "            base, _ = os.path.splitext(path_archivo)\n",
    "            sufijo = f\"_{sheet}\" if sheet else \"\"\n",
    "            path_salida = f\"{base}{sufijo}_columnas.txt\"\n",
    "        with open(path_salida, \"w\", encoding=\"utf-8\") as f:\n",
    "            for c in columnas:\n",
    "                f.write(f\"{c}\\n\")\n",
    "        print(f\"\\nArchivo de columnas guardado en: {path_salida}\")\n",
    "\n",
    "    return columnas\n",
    "\n",
    "# =========================\n",
    "# EJEMPLOS DE USO (quita el # y ajusta rutas):\n",
    "# columnas_csv = desglosar_columnas(\"ruta/archivo.csv\", encoding=\"latin-1\", guardar_txt=True)\n",
    "columnas_xlsx = desglosar_columnas(\"2023.xlsx\", sheet=\"Sheet1\", guardar_txt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a508b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de columnas: 24\n",
      "aÃ±o_ocu\n",
      "dÃ­a_ocu\n",
      "hora_ocu\n",
      "g_hora\n",
      "g_hora_5\n",
      "mes_ocu\n",
      "dÃ­a_sem_ocu\n",
      "depto_ocu\n",
      "mupio_ocu\n",
      "zona_ocu\n",
      "sexo_per\n",
      "edad_per\n",
      "g_edad_80ymÃ¡s\n",
      "g_edad_60ymÃ¡s\n",
      "edad_quinquenales\n",
      "mayor_menor\n",
      "tipo_veh\n",
      "marca_veh\n",
      "color_veh\n",
      "modelo_veh\n",
      "g_modelo_veh\n",
      "tipo_eve\n",
      "fall_les\n",
      "int_o_noint\n",
      "\n",
      "Archivo de columnas guardado en: fallecimientos_2014_2023_estandarizado_columnas.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def desglosar_columnas(path_archivo: str, sheet: str | None = None, encoding: str = \"utf-8\", guardar_txt: bool = False, path_salida: str | None = None):\n",
    "    \"\"\"\n",
    "    Lee SOLO los nombres de columnas de un CSV o Excel (.xlsx/.xls) y los devuelve como lista.\n",
    "    - path_archivo: ruta al archivo\n",
    "    - sheet: nombre de hoja (solo Excel). Si None, usa la primera hoja\n",
    "    - encoding: codificación para CSV (por defecto 'utf-8')\n",
    "    - guardar_txt: si True, guarda los nombres en un .txt\n",
    "    - path_salida: ruta del .txt a guardar. Si None, crea uno al lado del archivo\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(path_archivo)[1].lower()\n",
    "\n",
    "    if ext == \".csv\":\n",
    "        # Solo encabezado (rápido y liviano)\n",
    "        df = pd.read_csv(path_archivo, nrows=0, encoding=encoding)\n",
    "    elif ext in [\".xlsx\", \".xls\"]:\n",
    "        if sheet is None:\n",
    "            # Detectar primera hoja automáticamente\n",
    "            xls = pd.ExcelFile(path_archivo)\n",
    "            sheet = xls.sheet_names[0]\n",
    "        df = pd.read_excel(path_archivo, sheet_name=sheet, nrows=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Extensión no soportada: {ext}. Usa CSV o Excel (.xlsx/.xls).\")\n",
    "\n",
    "    columnas = list(map(str, df.columns))\n",
    "\n",
    "    # Mostrar en el notebook (orden natural)\n",
    "    print(f\"Total de columnas: {len(columnas)}\")\n",
    "    for c in columnas:\n",
    "        print(c)\n",
    "\n",
    "    # Guardar opcionalmente\n",
    "    if guardar_txt:\n",
    "        if path_salida is None:\n",
    "            base, _ = os.path.splitext(path_archivo)\n",
    "            sufijo = f\"_{sheet}\" if sheet else \"\"\n",
    "            path_salida = f\"{base}{sufijo}_columnas.txt\"\n",
    "        with open(path_salida, \"w\", encoding=\"utf-8\") as f:\n",
    "            for c in columnas:\n",
    "                f.write(f\"{c}\\n\")\n",
    "        print(f\"\\nArchivo de columnas guardado en: {path_salida}\")\n",
    "\n",
    "    return columnas\n",
    "\n",
    "# =========================\n",
    "# EJEMPLOS DE USO (quita el # y ajusta rutas):\n",
    "columnas_csv = desglosar_columnas(\"fallecimientos_2014_2023_estandarizado.csv\", encoding=\"latin-1\", guardar_txt=True)\n",
    "#columnas_xlsx = desglosar_columnas(\"fallecimientos_lesionados_totales_clean.csv\", sheet=\"Sheet1\", guardar_txt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3b7464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Convertido: fallecimientos_lesionados_totales_clean.csv → salida.xlsx (hoja: Datos)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def csv_a_excel(path_csv: str,\n",
    "                path_xlsx: str | None = None,\n",
    "                sheet_name: str = \"Sheet1\",\n",
    "                sep: str = \",\",\n",
    "                encoding: str = \"utf-8\",\n",
    "                dtype_backend: str = \"pyarrow\"):\n",
    "    \"\"\"\n",
    "    Convierte un archivo CSV a Excel (.xlsx).\n",
    "    - path_csv: ruta del CSV de entrada\n",
    "    - path_xlsx: ruta del Excel de salida (si None, usa el mismo nombre .xlsx)\n",
    "    - sheet_name: nombre de la hoja destino\n",
    "    - sep: separador del CSV (',' por defecto; usa ';' si tu CSV lo requiere)\n",
    "    - encoding: codificación (utf-8, latin-1, etc.)\n",
    "    - dtype_backend: 'pyarrow' (recomendado) o 'numpy'\n",
    "    \"\"\"\n",
    "    if path_xlsx is None:\n",
    "        base, _ = os.path.splitext(path_csv)\n",
    "        path_xlsx = base + \".xlsx\"\n",
    "\n",
    "    df = pd.read_csv(path_csv, sep=sep, encoding=encoding, dtype_backend=dtype_backend)\n",
    "    # Escribir a Excel\n",
    "    df.to_excel(path_xlsx, index=False, sheet_name=sheet_name)\n",
    "    print(f\"✅ Convertido: {path_csv} → {path_xlsx} (hoja: {sheet_name})\")\n",
    "\n",
    "# ==== Ejemplo de uso básico ====\n",
    "#csv_a_excel(\"fallecimientos_lesionados_totales_clean.csv\")  # genera datos.xlsx\n",
    "csv_a_excel(\"fallecimientos_lesionados_totales_clean.csv\", \"salida.xlsx\", sheet_name=\"Datos\", sep=\";\", encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62734951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javier Chiquin\\AppData\\Local\\Temp\\ipykernel_14928\\247098408.py:34: DtypeWarning: Columns (2,4,11,14,15,19,20,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"fallecimientos_2014_2023_estandarizado.csv\", encoding=\"utf-8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de columnas: 24\n",
      "ano_ocu\n",
      "dia_ocu\n",
      "hora_ocu\n",
      "g_hora\n",
      "g_hora_5\n",
      "mes_ocu\n",
      "dia_sem_ocu\n",
      "depto_ocu\n",
      "mupio_ocu\n",
      "zona_ocu\n",
      "sexo_per\n",
      "edad_per\n",
      "g_edad_80ymas\n",
      "g_edad_60ymas\n",
      "edad_quinquenales\n",
      "mayor_menor\n",
      "tipo_veh\n",
      "marca_veh\n",
      "color_veh\n",
      "modelo_veh\n",
      "g_modelo_veh\n",
      "tipo_eve\n",
      "fall_les\n",
      "int_o_noint\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def solo_letras(s: str, keep_digits_underscore: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza un texto:\n",
    "      - elimina tildes y diacríticos (áéíóúüñ → aeiouun)\n",
    "      - elimina caracteres no deseados\n",
    "      - comprime espacios/guiones en guion_bajo y limpia extremos\n",
    "    Si keep_digits_underscore=True, permite [a-z0-9_]; si False, solo [a-z].\n",
    "    \"\"\"\n",
    "    if s is None:\n",
    "        return s\n",
    "    # a) quitar espacios extremos\n",
    "    s = str(s).strip()\n",
    "    # b) normalizar y remover diacríticos\n",
    "    s = unicodedata.normalize(\"NFD\", s)\n",
    "    s = \"\".join(ch for ch in s if unicodedata.category(ch) != \"Mn\")  # sin marcas\n",
    "    # c) a minúsculas\n",
    "    s = s.lower()\n",
    "    # d) reemplazar separadores por \"_\"\n",
    "    s = re.sub(r\"[ \\t\\-./]+\", \"_\", s)\n",
    "    # e) filtrar caracteres\n",
    "    if keep_digits_underscore:\n",
    "        s = re.sub(r\"[^a-z0-9_]\", \"\", s)\n",
    "    else:\n",
    "        s = re.sub(r\"[^a-z]\", \"\", s)\n",
    "    # f) comprimir múltiples \"_\"\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    return s\n",
    "\n",
    "# ==== aplicar a un DataFrame ya cargado ====\n",
    "df = pd.read_csv(\"fallecimientos_2014_2023_estandarizado.csv\", encoding=\"utf-8\")\n",
    "df.columns = [solo_letras(c, keep_digits_underscore=True) for c in df.columns]\n",
    "\n",
    "print(\"Total de columnas:\", len(df.columns))\n",
    "for c in df.columns:\n",
    "    print(c)\n",
    "\n",
    "# (Opcional) guardar con encabezados limpios\n",
    "df.to_csv(\"fallecimientos_2014_2023_estandarizado2.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
